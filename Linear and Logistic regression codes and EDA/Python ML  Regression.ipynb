{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a vector Y and also create a data matrix X and using the results of OLS we will compute the  beta coefficients for a regression model $Y = b_0+b_1x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('E:\\\\Work\\\\Machine Learning Course\\\\Python\\\\Module 2 Linear Regression\\\\Data\\\\regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2          y\n",
      "0 -0.635764  0.241162 -32.718033\n",
      "1  0.644243  0.425391  59.923622\n",
      "2 -0.407295  0.865839   7.470409\n",
      "3 -0.551043  1.673688  30.181461\n",
      "4  1.354318 -0.459583  71.860641\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Ones']=np.repeat(1,data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2          y  Ones\n",
      "0 -0.635764  0.241162 -32.718033     1\n",
      "1  0.644243  0.425391  59.923622     1\n",
      "2 -0.407295  0.865839   7.470409     1\n",
      "3 -0.551043  1.673688  30.181461     1\n",
      "4  1.354318 -0.459583  71.860641     1\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['Ones','x1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are fitting a model, $Sales=b_0+b_1Tv+b_2Radio+b_3Newspaper$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ones        x1\n",
      "0     1 -0.635764\n",
      "1     1  0.644243\n",
      "2     1 -0.407295\n",
      "3     1 -0.551043\n",
      "4     1  1.354318\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -32.718033\n",
      "1    59.923622\n",
      "2     7.470409\n",
      "3    30.181461\n",
      "4    71.860641\n",
      "Name: y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Hessian=(X^TX)^-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hessian=np.linalg.inv(np.matmul(X.T,X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x=X^TY$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.matmul(X.T,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\beta}=Hessian \\times x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=np.matmul(Hessian,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.06851916,  65.04668995])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can get the predictions by computing the $\\hat{y}$ from the computed $\\hat{\\beta}$ and $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_hat=np.matmul(X,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RSS can be computed as $(\\hat{y}-Y)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RSS=np.sum((Y_hat-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1472501.4756470234"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Every time we might not want to compute the $\\beta$ vector using first principles, there  are python libraries such as scikitlearn that help us in estimating $\\beta$ vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=linear_model.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=reg.fit(X.drop('Ones',axis=1),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 65.04668995]\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0685191599872255]\n"
     ]
    }
   ],
   "source": [
    "print([reg.intercept_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will impliment gradient descent to minimize our cost function $RSS(\\beta)$. Let us list down the steps:\n",
    "1. Decide on the learning rate,lets call it $\\eta$, keep it small $10^-3 to 10^-6$\n",
    "2. Compute the gradient of $RSS(\\beta)$, this will equal $-2X^T(y-X\\beta) = -2X^T(y-\\hat{y})=-2X^T(Error)$\n",
    "3. Compute the differntial in $\\beta$ as $\\delta\\beta= -\\eta (2X^T(Error))$\n",
    "4. Update $\\beta$ as $\\beta_{new}=\\beta_{old}+\\delta\\beta$\n",
    "4. Keep on doing this until n_iters are exhausted or difference between succesive costs is less than some level of tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,n_iter,eta=0.001):\n",
    "    beta=np.ones(X.shape[1])\n",
    "    cost_history=[]\n",
    "    converged=False\n",
    "    for i in range(n_iter):\n",
    "        if converged==True:\n",
    "            break\n",
    "        y_hat=np.matmul(X,beta)\n",
    "        Error=y-y_hat\n",
    "        J=np.sum(Error**2)\n",
    "        Gradient=-2*np.matmul(X.T,Error)\n",
    "        beta=beta-eta*Gradient# Beta update\n",
    "        cost_history.append(J)\n",
    "        if i>1:\n",
    "            if abs(cost_history[i]-cost_history[i-1])<=0.0003:\n",
    "                converged=True\n",
    "    print(converged)\n",
    "    plt.plot(np.arange(i),np.array(cost_history),'-r')\n",
    "    plt.ylim(ymin=0,ymax=1000)\n",
    "    print(\"cost in %sth iteration is %f\"%(i+1,J))\n",
    "    print(\"cost in 1st iteration is %f\"%cost_history[0])\n",
    "    return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cost in 39234th iteration is 1472502.238479\n",
      "cost in 1st iteration is 5541205.077211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.06259162,  65.01946737])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD5pJREFUeJzt3H/MnWddx/H3xxY22PixSdPUtnElaVw6ovx4UocQQpi6\nMQmdiVlKgjRmsX8wEfwR0kqi+McSNEqQ6NAKaJXJqIBZQ4JYConxD1afssHWjtrCNtbaX2hg6h+D\njq9/nO/g2D1P1uec0+ec1fcreXKuc93Xdd/fXjnP8+l9n/ucVBWSJP3ItAuQJM0GA0GSBBgIkqRm\nIEiSAANBktQMBEkScAGBkOSjSc4keXCo7+ok+5Ic7cerhrbtTHIsyZEkNw71vyrJA73tg0ky+X+O\nJGlUF3KG8NfATef17QD2V9VGYH8/J8kmYCtwXc+5M8mKnvMh4FeBjf1z/j4lSVP0jIFQVf8M/Od5\n3VuA3d3eDdwy1H93VT1RVQ8Dx4DNSdYAL6yqL9Xgk3B/MzRHkjQDVo44b3VVnez2KWB1t9cCXxoa\nd7z7vtft8/sXlGQ7sB3giiuueNW11147YpmS9P/TwYMHv1VVq5YyZ9RA+IGqqiQT/f6LqtoF7AKY\nm5ur+fn5Se5eki55SR5d6pxR7zI63ZeB6Mcz3X8CWD80bl33nej2+f2SpBkxaiDsBbZ1extwz1D/\n1iSXJdnA4M3jA3156fEk1/fdRW8bmiNJmgHPeMkoyceB1wMvSXIc+D3gfcCeJLcBjwK3AlTVoSR7\ngMPAOeD2qnqyd/V2BncsPQ/4bP9IkmZEZv3rr30PQZKWLsnBqppbyhw/qSxJAgwESVIzECRJgIEg\nSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLUDARJEmAgSJKagSBJ\nAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLU\nDARJEmAgSJKagSBJAgwESVIzECRJwJiBkOQ3khxK8mCSjye5PMnVSfYlOdqPVw2N35nkWJIjSW4c\nv3xJ0qSMHAhJ1gK/DsxV1cuAFcBWYAewv6o2Avv7OUk29fbrgJuAO5OsGK98SdKkjHvJaCXwvCQr\ngecD/w5sAXb39t3ALd3eAtxdVU9U1cPAMWDzmMeXJE3IyIFQVSeAPwK+CZwEvlNV/wSsrqqTPewU\nsLrba4HHhnZxvPueJsn2JPNJ5s+ePTtqiZKkJRjnktFVDP7XvwH4MeCKJG8dHlNVBdRS911Vu6pq\nrqrmVq1aNWqJkqQlGOeS0c8CD1fV2ar6HvBp4GeA00nWAPTjmR5/Alg/NH9d90mSZsA4gfBN4Pok\nz08S4AbgIWAvsK3HbAPu6fZeYGuSy5JsADYCB8Y4viRpglaOOrGq7k3ySeDLwDngPmAXcCWwJ8lt\nwKPArT3+UJI9wOEef3tVPTlm/ZKkCcngMv/smpubq/n5+WmXIUnPKkkOVtXcUub4SWVJEmAgSJKa\ngSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgAD\nQZLUDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNB\nkgQYCJKkZiBIkgADQZLUDARJEmAgSJLaWIGQ5MVJPpnka0keSvLqJFcn2ZfkaD9eNTR+Z5JjSY4k\nuXH88iVJkzLuGcKfAP9YVdcCPwU8BOwA9lfVRmB/PyfJJmArcB1wE3BnkhVjHl+SNCEjB0KSFwGv\nAz4CUFXfrapvA1uA3T1sN3BLt7cAd1fVE1X1MHAM2Dzq8SVJkzXOGcIG4CzwV0nuS/LhJFcAq6vq\nZI85Bazu9lrgsaH5x7vvaZJsTzKfZP7s2bNjlChJulDjBMJK4JXAh6rqFcD/0JeHnlJVBdRSd1xV\nu6pqrqrmVq1aNUaJkqQLNU4gHAeOV9W9/fyTDALidJI1AP14prefANYPzV/XfZKkGTByIFTVKeCx\nJD/RXTcAh4G9wLbu2wbc0+29wNYklyXZAGwEDox6fEnSZK0cc/47gLuSPBf4BvArDEJmT5LbgEeB\nWwGq6lCSPQxC4xxwe1U9OebxJUkTMlYgVNX9wNwCm25YZPwdwB3jHFOSdHH4SWVJEmAgSJKagSBJ\nAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQYCJKkZiBIkgADQZLU\nDARJEmAgSJKagSBJAgwESVIzECRJgIEgSWoGgiQJMBAkSc1AkCQBBoIkqRkIkiTAQJAkNQNBkgQY\nCJKkZiBIkgADQZLUDARJEmAgSJKagSBJAiYQCElWJLkvyWf6+dVJ9iU52o9XDY3dmeRYkiNJbhz3\n2JKkyZnEGcI7gYeGnu8A9lfVRmB/PyfJJmArcB1wE3BnkhUTOL4kaQLGCoQk64BfAD481L0F2N3t\n3cAtQ/13V9UTVfUwcAzYPM7xJUmTM+4ZwgeAdwPfH+pbXVUnu30KWN3ttcBjQ+OOd9/TJNmeZD7J\n/NmzZ8csUZJ0IUYOhCRvAs5U1cHFxlRVAbXUfVfVrqqaq6q5VatWjVqiJGkJVo4x9zXAm5PcDFwO\nvDDJx4DTSdZU1ckka4AzPf4EsH5o/rrukyTNgJHPEKpqZ1Wtq6prGLxZ/IWqeiuwF9jWw7YB93R7\nL7A1yWVJNgAbgQMjVy5JmqhxzhAW8z5gT5LbgEeBWwGq6lCSPcBh4Bxwe1U9eRGOL0kaQQaX+WfX\n3Nxczc/PT7sMSXpWSXKwquaWMsdPKkuSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaC\nJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJ\nUjMQJEmAgSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktRGDoQk\n65N8McnhJIeSvLP7r06yL8nRfrxqaM7OJMeSHEly4yT+AZKkyRjnDOEc8FtVtQm4Hrg9ySZgB7C/\nqjYC+/s5vW0rcB1wE3BnkhXjFC9JmpyRA6GqTlbVl7v9X8BDwFpgC7C7h+0Gbun2FuDuqnqiqh4G\njgGbRz2+JGmyJvIeQpJrgFcA9wKrq+pkbzoFrO72WuCxoWnHu2+h/W1PMp9k/uzZs5MoUZL0DMYO\nhCRXAp8C3lVVjw9vq6oCaqn7rKpdVTVXVXOrVq0at0RJ0gUYKxCSPIdBGNxVVZ/u7tNJ1vT2NcCZ\n7j8BrB+avq77JEkzYJy7jAJ8BHioqt4/tGkvsK3b24B7hvq3JrksyQZgI3Bg1ONLkiZr5RhzXwP8\nMvBAkvu773eA9wF7ktwGPArcClBVh5LsAQ4zuEPp9qp6cozjS5ImaORAqKp/AbLI5hsWmXMHcMeo\nx5QkXTx+UlmSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmAgSBJagaCJAkwECRJ\nzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSAANBktQMBEkSYCBIkpqBIEkCDARJUjMQJEmA\ngSBJagaCJAkwECRJzUCQJAEGgiSpGQiSJMBAkCQ1A0GSBBgIkqRmIEiSgCkEQpKbkhxJcizJjuU+\nviRpYcsaCElWAH8GvBHYBLwlyablrEGStLDlPkPYDByrqm9U1XeBu4Ety1yDJGkBK5f5eGuBx4ae\nHwd++vxBSbYD2/vpfyc5MuLxXgJ8a8S5F9us1jardYG1jcralm5W64ILr+3Hl7rj5Q6EC1JVu4Bd\n4+4nyXxVzU2gpImb1dpmtS6wtlFZ29LNal1wcWtb7ktGJ4D1Q8/XdZ8kacqWOxD+FdiYZEOS5wJb\ngb3LXIMkaQHLesmoqs4l+TXgc8AK4KNVdegiHnLsy04X0azWNqt1gbWNytqWblbrgotYW6rqYu1b\nkvQs4ieVJUmAgSBJapdkIEzr6zGSPJLkgST3J5nvvquT7EtytB+vGhq/s2s8kuTGof5X9X6OJflg\nkoxQy0eTnEny4FDfxGpJclmST3T/vUmuGaOu9yY50et2f5Kbl7uunrs+yReTHE5yKMk7Z2jdFqtt\nqmuX5PIkB5J8pev6/Rlas8Vqm4nXW89fkeS+JJ+ZiXWrqkvqh8Gb1V8HXgo8F/gKsGmZjv0I8JLz\n+v4Q2NHtHcAfdHtT13YZsKFrXtHbDgDXAwE+C7xxhFpeB7wSePBi1AK8Hfjzbm8FPjFGXe8FfnuB\nsctWV49fA7yy2y8A/q1rmIV1W6y2qa5d7+PKbj8HuLf3PQtrtlhtM/F66zm/Cfwd8JlZ+B296H8k\nl/sHeDXwuaHnO4Gdy3TsR3h6IBwB1nR7DXBkoboY3Hn16h7ztaH+twB/MWI91/B///BOrJanxnR7\nJYNPTmbEuhb7BV3WuhY4/j3Az83Kui1S28ysHfB84MsMvn1gptbsvNpmYs0YfA5rP/AGfhgIU123\nS/GS0UJfj7F2mY5dwOeTHMzg6zcAVlfVyW6fAlZ3e7E613b7/P5JmGQtP5hTVeeA7wA/OkZt70jy\n1QwuKT11mjy1uvr0+hUM/lc5U+t2Xm0w5bXryx73A2eAfVU1M2u2SG0wG6+3DwDvBr4/1DfVdbsU\nA2GaXltVL2fwba63J3nd8MYaRPVM3Oc7S7UAH2Jwie/lwEngj6dZTJIrgU8B76qqx4e3TXvdFqht\n6mtXVU/2634dsDnJy87bPrU1W6S2qa9ZkjcBZ6rq4GJjprFul2IgTO3rMarqRD+eAf6Bwbe7nk6y\nBqAfzzxDnSe6fX7/JEyylh/MSbISeBHwH6MUVVWn+xf3+8BfMli3qdSV5DkM/uDeVVWf7u6ZWLeF\napultauqbwNfBG5iRtZsodpmZM1eA7w5ySMMvvX5DUk+xpTX7VIMhKl8PUaSK5K84Kk28PPAg33s\nbT1sG4Nrv3T/1r4TYAOwETjQp4uPJ7m+7xZ429CccU2yluF9/RLwhf4fzZI99QvQfpHBui17Xb2v\njwAPVdX7hzZNfd0Wq23aa5dkVZIXd/t5DN7X+BqzsWYL1jbtNQOoqp1Vta6qrmHwN+oLVfVWpr1u\nS3lj5tnyA9zM4C6MrwPvWaZjvpTBXQBfAQ49dVwG1+z2A0eBzwNXD815T9d4hKE7iYA5Bi/SrwN/\nymhvOn6cwenw9xhcV7xtkrUAlwN/DxxjcJfDS8eo62+BB4Cv9ot4zXLX1XNfy+AU/avA/f1z84ys\n22K1TXXtgJ8E7uvjPwj87qRf92Os2WK1zcTrbWjfr+eHbypPdd386gpJEnBpXjKSJI3AQJAkAQaC\nJKkZCJIkwECQJDUDQZIEGAiSpPa/18t+yxk480QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c230babf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradientDescent(X,y=Y,n_iter=100000,eta=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's impliment a very naive version of Stochastic Gradient Descent, here again the aim is to minimize $RSS(\\beta)$\n",
    "1. Decide on the learning rate, $\\eta$ and also decide on the number of epochs or iterations\n",
    "2. In each iteration compute $\\beta$, $\\delta\\beta$ and the $\\bigtriangledown RSS(\\beta)$\n",
    "3. Stop when the number of iterations exhaust or convergence is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(d,n_iter,eta,s):\n",
    "    beta=np.ones(d.shape[1]-1)\n",
    "    cost_history=[]\n",
    "    for i in range(n_iter):\n",
    "        Data_Sample=d.sample(frac=s)\n",
    "        y=Data_Sample['Y']\n",
    "        x=Data_Sample.drop('Y',axis=1)\n",
    "        y_hat=np.matmul(x,beta)\n",
    "        Error=y-y_hat\n",
    "        J=np.sum(Error**2)\n",
    "        Gradient=-2*np.matmul(x.T,Error)\n",
    "        beta=beta-eta*Gradient\n",
    "        cost_history.append(J)\n",
    "    plt.plot(np.arange(n_iter),np.array(cost_history),'-r')\n",
    "    plt.ylim(ymin=0,ymax=1000)\n",
    "    print(\"cost in %sth iteration is %f\"%(i+1,J))\n",
    "    print(\"cost in 1st iteration is %f\"%cost_history[0])\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d=X.copy()\n",
    "X_d['Y']=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost in 100000th iteration is 870684.406846\n",
      "cost in 1st iteration is 3363550.340009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -1.04794857,  65.03263145])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c236e96080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd(d=X_d,n_iter=100000,eta=0.0000001,s=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
